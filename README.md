# llm_inference_engine_benchmark
This repository aims to evaluate various open-source inference frameworks, analyzing their strengths and weaknesses.
    **Hardware**: Nvidia H800
    
    **LLM model**: llama2 
    
    **llm inference engine**: llama.cpp
    
    **指标**: thoughtput, 
  
